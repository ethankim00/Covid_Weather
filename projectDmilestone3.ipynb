{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Weather-Data-EDA\" data-toc-modified-id=\"Weather-Data-EDA-1\">Weather Data EDA</a></span></li><li><span><a href=\"#Mobility-Data-EDA\" data-toc-modified-id=\"Mobility-Data-EDA-2\">Mobility Data EDA</a></span></li><li><span><a href=\"#Standardize-and-Add-Variables\" data-toc-modified-id=\"Standardize-and-Add-Variables-3\">Standardize and Add Variables</a></span></li><li><span><a href=\"#Linear-Regressions\" data-toc-modified-id=\"Linear-Regressions-4\">Linear Regressions</a></span></li><li><span><a href=\"#Aggregate-Predictors-for-LSTM\" data-toc-modified-id=\"Aggregate-Predictors-for-LSTM-5\">Aggregate Predictors for LSTM</a></span></li><li><span><a href=\"#Run-GRU-and-LSTM-Models\" data-toc-modified-id=\"Run-GRU-and-LSTM-Models-6\">Run GRU and LSTM Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Discussion-of-RNN-Models\" data-toc-modified-id=\"Discussion-of-RNN-Models-6.1\">Discussion of RNN Models</a></span></li></ul></li><li><span><a href=\"#Aggregate-Data-by-County\" data-toc-modified-id=\"Aggregate-Data-by-County-7\">Aggregate Data by County</a></span></li><li><span><a href=\"#Regression-on-R-proxy-Values-and-Predictors\" data-toc-modified-id=\"Regression-on-R-proxy-Values-and-Predictors-8\">Regression on R-proxy Values and Predictors</a></span><ul class=\"toc-item\"><li><span><a href=\"#Discussion-of-Regressions\" data-toc-modified-id=\"Discussion-of-Regressions-8.1\">Discussion of Regressions</a></span></li></ul></li><li><span><a href=\"#Sources:\" data-toc-modified-id=\"Sources:-9\">Sources:</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "CCWhx6cNZBna",
    "outputId": "d2bdc818-d22c-4f7b-955e-eafeac3ceca4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS\n",
    "\n",
    "import plotly.figure_factory as ff\n",
    "import plotly\n",
    "\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import backend\n",
    "\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.layers import Input, SimpleRNN, Embedding, Dense, TimeDistributed, GRU, \\\n",
    "                          Dropout, Bidirectional, Conv1D, BatchNormalization, LSTM\n",
    "\n",
    "print(tf.keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yldSwz9dZPGy"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "%cd drive/My\\ Drive/Colab\\ Notebooks/data/Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "colab_type": "code",
    "id": "YpMTdmruZBns",
    "outputId": "9e09250d-8695-4c97-8956-3dfb717ca200"
   },
   "outputs": [],
   "source": [
    "# DATA PRE-PROCESSING\n",
    "# Pre-processed data saved in external csv for ease of use\n",
    "\n",
    "# import county level COVID-19 data\n",
    "df_counties = pd.read_csv('COVID-19-Midas/data/cases/USA/nytimes_covid19_data/20200507_us-counties.csv')\n",
    "df_counties['date_county'] = df_counties['date'] + ' ' + df_counties['county'] + ' ' + df_counties['state']\n",
    "\n",
    "# import county level weather data\n",
    "df_temperature = pd.read_csv('temperature_data.csv')\n",
    "df_rain = pd.read_csv('rain_data.csv')\n",
    "df_sun = pd.read_csv('sun_data.csv')\n",
    "\n",
    "# import county level population density data\n",
    "df_density = pd.read_csv('county_density.csv').dropna()\n",
    "df_density['GCT_STUB.display-label'] = df_density['GCT_STUB.display-label'].apply(lambda x: x.replace(' County', ''))\n",
    "df_density['state_county'] = df_density['GEO.display-label'] + ' ' + df_density['GCT_STUB.display-label']\n",
    "\n",
    "# import county level mobility data from Google's data reports\n",
    "df_movement = pd.read_csv('Global_Mobility_Report.csv')\n",
    "df_movement = df_movement.loc[df_movement['country_region_code'] == 'US']\n",
    "df_movement = df_movement.dropna().reset_index()\n",
    "df_movement['sub_region_2'] = df_movement['sub_region_2'].apply(lambda x: x.replace(' County', ''))\n",
    "df_movement['date_county'] = df_movement['date'] + ' ' + df_movement['sub_region_2'] + ' ' + df_movement['sub_region_1']\n",
    "date_counties = np.array(df_counties['date_county'])\n",
    "\n",
    "# match date county data accross mobility and COVID data \n",
    "df_movement = df_movement.loc[df_movement['date_county'].apply(lambda x: x in date_counties)]\n",
    "\n",
    "# merge the matched data\n",
    "df_merged = df_counties.join(df_movement.set_index('date_county'), how ='right', on='date_county', rsuffix='_other')\n",
    "\n",
    "# drop redundant columns from the merge\n",
    "df_merged = df_merged.drop(['sub_region_1', 'sub_region_2', 'date_other', 'index', 'country_region_code'], axis=1).reset_index(drop=True)\n",
    "df_merged['fips'] = df_merged['fips'].apply(lambda x: int(x))\n",
    "df_merged['state_county'] = df_merged['state'] + ' ' + df_merged['county']\n",
    "\n",
    "# match weather data to county by FIP and date\n",
    "temps = []\n",
    "rains = []\n",
    "suns = []\n",
    "for row in df_merged.itertuples():\n",
    "    try:\n",
    "        temps.append(df_temperature.loc[df_temperature['date'] == row.date][str(row.fips)].values[0])\n",
    "        rains.append(df_rain.loc[df_rain['date'] == row.date][str(row.fips)].values[0])\n",
    "        suns.append(df_sun.loc[df_sun['date'] == row.date][str(row.fips)].values[0])\n",
    "    except:\n",
    "        temps.append(None)\n",
    "        rains.append(None)\n",
    "        suns.append(None)\n",
    "  \n",
    "\n",
    "# create weather columns\n",
    "df_merged['temperature'] = temps\n",
    "df_merged['temperature'] = pd.to_numeric(df_merged['temperature'], errors='coerce')\n",
    "df_merged['rain'] = rains\n",
    "df_merged['sun'] = suns\n",
    "\n",
    "# match density data by state county\n",
    "densities = []\n",
    "for row in df_merged.itertuples():\n",
    "    try:\n",
    "        densities.append(df_density.loc[df_density['state_county'] == row.state_county]['Density'].values[0])\n",
    "    except:\n",
    "        densities.append(None)\n",
    "\n",
    "# create density column\n",
    "df_merged['density'] = densities\n",
    "\n",
    "# remove missing data\n",
    "df_merged = df_merged.dropna()\n",
    "\n",
    "# save pre-processed data for easier access\n",
    "df_merged.to_csv('agg_county_data.csv')\n",
    "\n",
    "# preview data\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uoY-2jfqYH6h"
   },
   "source": [
    "Our goal for this part of the project was to elucidate the effect of weather on compliance with social distancing measures. We hypothesized that people would be more prone to leaving their houses on day where the weather was nice. We aggregated daily values for precipitation in inches, temperature in Fahrenheit and hours of sunlight for each county in the United States. To evaluate social distancing measures, we used data from Google Mobility Reports which tracks anonymize cellphone movements. Starting February 13th, 2020 we have daily percent change from the baseline at the beginning of the period for trips to retail and recreation centers, parks, transit stations and residential areas. For example we might see that in a certain county, on May 10th, there was a 40% decrease in park visits relative to baseline. By looking at this data we can determine how warmer temperatures and changing weather patterns in the summer months may effect social distancing measures. We believe that this may an additional factor to take into account admist claims of reduced r0 values due to warmer weather. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n7VOQKXecx32"
   },
   "source": [
    "# Weather Data EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wh8Tg7xqXssY",
    "outputId": "cafa308e-1af1-44a8-b615-f234c82e54c4"
   },
   "outputs": [],
   "source": [
    "weather_data = {'rain':df_rain, 'sun': df_sun, 'temp': df_temperature}\n",
    "\n",
    "def get_weather_df(weather, date):\n",
    "    data = weather_data[weather]\n",
    "    df = pd.DataFrame(columns = ['fips', weather])\n",
    "    df['fips'] = data[data['date']== date].columns[:-1]\n",
    "    df[weather] = list(data[data['date'] == date].iloc[0,:-1])\n",
    "    df = df.loc[df[weather] != date]\n",
    "    df[weather] = df[weather].loc[df[weather] != date].astype(float)\n",
    "    return df\n",
    "\n",
    "def plot_weather(weather, date):\n",
    "    df = get_weather_df(weather, date)\n",
    "    start = np.min(df[weather].astype(float))\n",
    "    stop = max(df[weather].astype(float))\n",
    "    fig = px.choropleth_mapbox(df, geojson=counties, locations='fips', color=weather,\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           range_color=(start, stop),\n",
    "                           mapbox_style=\"carto-positron\",\n",
    "                           zoom=3, center = {\"lat\": 37.0902, \"lon\": -95.7129},\n",
    "                           opacity=0.5,\n",
    "                           labels={weather:weather}\n",
    "                          )\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "    fig.show()\n",
    "\n",
    "# plot temperature, rain, and sun\n",
    "plot_weather('temp', '2020-02-15')\n",
    "plot_weather('rain', '2020-02-15')\n",
    "plot_weather('sun', '2020-02-15')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-QQlZhSEciZJ"
   },
   "source": [
    "Above, we can see generally warmer temperatures in the Southern regions of the country, Also 6 states are missing data for this date. There was also a large amount of rain in the Pacific Northwest. Also on this date, hours of sunlight seem to have been severely reduced by cloud cover in the Pacific Northwest and parts of the Midwest and South."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FN7LqKHDc5FG"
   },
   "source": [
    "# Mobility Data EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4IAeS0x3cvLY"
   },
   "outputs": [],
   "source": [
    "indices = ['retail_and_recreation_percent_change_from_baseline',\n",
    "       'grocery_and_pharmacy_percent_change_from_baseline',\n",
    "       'parks_percent_change_from_baseline',\n",
    "       'transit_stations_percent_change_from_baseline',\n",
    "       'workplaces_percent_change_from_baseline',\n",
    "       'residential_percent_change_from_baseline']\n",
    "\n",
    "data = pd.read_csv('agg_county_data.csv', parse_dates = ['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "avods2qRc_Nc"
   },
   "outputs": [],
   "source": [
    "def plot_mobility(data, index, date):\n",
    "    df = data[data['date'] == date][['fips', index]]\n",
    "    start = np.min(df[index].astype(float))\n",
    "    stop = np.max(df[index].astype(float))\n",
    "    fig = px.choropleth_mapbox(df, geojson=counties, locations='fips', color=index,\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           range_color=(start, stop),\n",
    "                           mapbox_style=\"carto-positron\",\n",
    "                           zoom=3, center = {\"lat\": 37.0902, \"lon\": -95.7129},\n",
    "                           opacity=0.5,\n",
    "                           labels={index:index}\n",
    "                          )\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "hJfUkW6pdBsV",
    "outputId": "05b064c6-db7d-4be8-8d5d-1e179f35b88f"
   },
   "outputs": [],
   "source": [
    "# Look at mobility indices near beginning of time period\n",
    "for index in indices:\n",
    "    plot_mobility(data, index, '2020-03-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "KAS7OmmTdCSX",
    "outputId": "8f959f92-036a-41e1-ee23-b593e777d031"
   },
   "outputs": [],
   "source": [
    "# Look at mobility indices near end of time period\n",
    "for index in indices:\n",
    "    plot_mobility(data, index, '2020-04-10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uykyp3opdbEc"
   },
   "source": [
    "Unfortunately google did not have a large degree of coverage for county level data during this time period. Towards the end of the time period studied we have mobility data for around 500 counties. For all the mobility indices besides residential, generally we see a negative change from baseline as people avoid these areas. The change from baseline for residential is positive as people remained at home more under stay-at-home orders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kkl0rmD_dp9c"
   },
   "source": [
    "# Standardize and Add Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hiuf6zVod0vD"
   },
   "source": [
    "The weather varibles are standardized to account for regional variation in weather patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vT-09pidduqa"
   },
   "outputs": [],
   "source": [
    "# Standardize weather values in each county\n",
    "def standardize_df(df, columns):\n",
    "    scaler = StandardScaler()\n",
    "    for column in columns:\n",
    "        df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "        fitted = scaler.fit(df[[column]])\n",
    "        df[[column]] = scaler.transform(df[[column]])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "quOdYCS6dxYj"
   },
   "outputs": [],
   "source": [
    "data = standardize_df(data, ['rain', 'sun', 'temperature'])\n",
    "# Add indicators for day of week\n",
    "data['weekday'] = data['date'].map(lambda x: x.weekday())\n",
    "# Get number of days since beginning of time period\n",
    "start = data['date'][0]\n",
    "data['days'] = data['date'].map(lambda x: (x - start).days)\n",
    "# One hot encode\n",
    "data = pd.get_dummies(data, prefix=['weekday'], columns = ['weekday'])\n",
    "# Add in weekdays for plotting \n",
    "data['weekday'] = data['date'].map(lambda x: x.weekday())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZOu26QEveI2N"
   },
   "source": [
    "We add two new variables: the day of the week and the number of days since the beginning of the time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-G-Ym7noeJnm"
   },
   "outputs": [],
   "source": [
    "# Choose predictors and target \n",
    "target = 'parks_percent_change_from_baseline'\n",
    "predictors = ['sun', 'rain', 'weekday_0', 'weekday_1', 'weekday_2', 'weekday_3',\n",
    "       'weekday_4', 'weekday_5', 'weekday_6', 'temperature', 'days']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BPPAVFDYeLjC"
   },
   "source": [
    "# Linear Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KTk0AkuGeQtB"
   },
   "outputs": [],
   "source": [
    "def fit_OLS(data, predictors, target):\n",
    "    data = data.dropna()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data.loc[:, predictors], \n",
    "                                                         data[target], test_size=0.2, \n",
    "                                                         random_state = 109)\n",
    "    X_train =  sm.add_constant(X_train)\n",
    "    X_test =  sm.add_constant(X_test)\n",
    "    OLS = sm.OLS(y_train,X_train, missing = 'drop')\n",
    "    OLS = OLS.fit()\n",
    "    r2 = sklearn.metrics.r2_score(y_test, OLS.predict(X_test))\n",
    "    print('Test R2 is: {}'.format(r2))\n",
    "    return OLS\n",
    "def plot(data):\n",
    "    sns.regplot(data['days'], data[target])\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    sns.regplot(data['sun'], data[target])\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    sns.regplot(data['temperature'], data[target])\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    sns.regplot(data['rain'], data[target])\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    plt.scatter(data['weekday'], data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 705
    },
    "colab_type": "code",
    "id": "EA8qO4mfeSBt",
    "outputId": "a59add8d-486d-4405-bcae-2e4523df9866"
   },
   "outputs": [],
   "source": [
    "OLS = fit_OLS(data, predictors, target)\n",
    "OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DTbms605eX04",
    "outputId": "cbc07e9f-3b9a-4982-d50f-d6887484bf71"
   },
   "outputs": [],
   "source": [
    "plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mELd6wdLehfI"
   },
   "source": [
    "We focus on visits to parks as these are the types of nonessential visits that should be avoided in order to mitigate risk and are the most likely to be affected by the weather. In the aggregated data, we see a slight decrease in visits over times. This contrasts to sharp, sudden declines in some of the other metrics (see plot below). While retial and recreation visits dropped precipitously around mid March in resonse to quarantine orders,\n",
    "visits to parks exhibited a less clear trend. For parks, a 1 standard deviation increase in the hours of sunlight relative to baseline was associated with an average increase in visits to parks of 22% relative to baseline. Interestingly, temperature had a slightly negative effect. Rain had a pronounced effect with larger levels of precipitation leading to fewer visits to parks. The day of the week did not have as pronounced an effect as might be expected as people seemed to go to parks more on Mondays and Tuesdays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "GjfieoRYejjA",
    "outputId": "b99fcb3a-b56f-4f1c-c9f9-44234f297836"
   },
   "outputs": [],
   "source": [
    "plt.scatter(data['days'],data['retail_and_recreation_percent_change_from_baseline'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 705
    },
    "colab_type": "code",
    "id": "JI-VmPl5elol",
    "outputId": "112548a2-ea9f-4ce7-a475-fbf8f4df32de"
   },
   "outputs": [],
   "source": [
    "# Fit for state of Massachusetts\n",
    "mass = data[data['state']== 'Massachusetts']\n",
    "\n",
    "OLS = fit_OLS(mass, predictors, target)\n",
    "OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "CS7MAPEKenjC",
    "outputId": "ad84fd15-9c64-4cfe-c7de-f1f379fce254"
   },
   "outputs": [],
   "source": [
    "plot(mass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9k9NBG6cepxv"
   },
   "source": [
    "We perform the same analysis for the state of Massachussets because it had a large degree of coverage in terms of counties represented in the dataset. On the state level, the effects are more pronounced with a larger $r^2$ value compared to for the entire country. Interestingly, the effect of temperature seems to be reversed and people go to the park more on warmer days. This may be a result of colder average temperatures in this region leading warmer days to fall in the sweet spot for going out. Another interesting result is a pronounced increase in park visits on Saturdays. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RRciwOZeeqZt"
   },
   "source": [
    "Based on our analysis we conclude that there is a robust relationship between visits to parks and weather. Warmer temperatures in the summer may lead to less compliance in Northern regions and more compliance in Southern regions. Drought conditions, espeically may influence people to seek out parks more. Finally spikes in visits on certain days of the week may indicate the efficacy of stagerring weekends for those who are working at home to prevent large numbers of people from visiting parks at the same time. Next, we will evaluate if we can use this weather data to directly predict Covid-19 case counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FupP8VXDervn"
   },
   "source": [
    "# Aggregate Predictors for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "FXZDReQs4FDp",
    "outputId": "7c03f8e3-1f4c-41ad-c799-3512a9f36c22"
   },
   "outputs": [],
   "source": [
    "# import saved pre-processed data\\\n",
    "df_merged = pd.read_csv('agg_county_data.csv')\n",
    "\n",
    "# split into series by county\n",
    "split = []\n",
    "for fip in df_merged['fips'].unique():\n",
    "    split.append(df_merged.loc[df_merged['fips'] == fip])\n",
    "\n",
    "# seperate predictors from cases to get\n",
    "# X - a time-series of 10 predictors: temperature, sunshine, rain, \n",
    "#   population density and mobility in retail, grocery/pharmacy, parks, transit, work, and residential\n",
    "# y - a time-series of COVID-19 cases\n",
    "\n",
    "X = [[(tup.retail_and_recreation_percent_change_from_baseline, tup.grocery_and_pharmacy_percent_change_from_baseline,\n",
    "   tup.parks_percent_change_from_baseline,tup.transit_stations_percent_change_from_baseline, \n",
    "   tup.workplaces_percent_change_from_baseline, tup.residential_percent_change_from_baseline, \n",
    "   tup.temperature, tup.rain, tup.sun, tup.density) for tup in x.itertuples()] for x in split]\n",
    "\n",
    "y = [[tup.cases for tup in x.itertuples()] for x in split]\n",
    "\n",
    "# pad the data to make each series the same length\n",
    "for i, county in enumerate(X):\n",
    "    while len(county) < max([len(x) for x in X]):\n",
    "        y[i].insert(0,0)\n",
    "        county.insert(0,(0, 0, 0, 0, 0, 0, 0, 0, 0, 0))\n",
    "\n",
    "# split data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "X_train[0][-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FmqXrWhOk7u5"
   },
   "outputs": [],
   "source": [
    "# function from previous HW to plot loss over epochs\n",
    "def plot_training_history(history):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1,len(loss)+1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wFP6ND_vltG5"
   },
   "source": [
    "# Run GRU and LSTM Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8z5QqvHdlw8l"
   },
   "source": [
    "We attempted to model COVID-19 cases in each county using GRU and LSTM models. We experimented with two different types of models (GRU and LSTM) as well as various types of inputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z_lOcpffmwOL"
   },
   "source": [
    "First we used a GRU model using the cumulative cases for each county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "d1NAsdq9Vxdh",
    "outputId": "ff1920df-0903-4c3a-9601-43d86952c37c"
   },
   "outputs": [],
   "source": [
    "# GRU model parameters\n",
    "hidden_neurons = 100\n",
    "optimizer = \"adam\"\n",
    "loss = \"MSE\"\n",
    "batch_size = 8\n",
    "epochs = 400\n",
    "verbose = 2\n",
    "\n",
    "# define GRU model\n",
    "model_gru = Sequential()\n",
    "model_gru.add(Input(shape=(68, 10)))\n",
    "model_gru.add(GRU(hidden_neurons, return_sequences = True))\n",
    "model_gru.add(TimeDistributed(Dense(1, activation = 'relu')))\n",
    "\n",
    "# compile GRU model\n",
    "model_gru.compile(optimizer=optimizer, loss=loss)\n",
    "model_gru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ubF6m-0pIuB-",
    "outputId": "870d6d97-1d07-4ac4-c2da-808ee58f3290"
   },
   "outputs": [],
   "source": [
    "# fit model\n",
    "history_gru = model_gru.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, \n",
    "                    validation_data=(X_test, y_test), verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7El-oWUYm0dv"
   },
   "source": [
    "Then we used a GRU model on the log of the number of cases in order to provide the model with a simpler, linear model to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "Eji0eOOjVsia",
    "outputId": "5cfb43d7-1e1d-4663-bcac-e8d5b4c64d61"
   },
   "outputs": [],
   "source": [
    "# GRU model on log cases\n",
    "hidden_neurons = 100\n",
    "optimizer = \"adam\"\n",
    "loss = \"MSE\"\n",
    "batch_size = 8\n",
    "epochs = 400\n",
    "verbose = 2\n",
    "\n",
    "# define GRU model\n",
    "model_gru_log = Sequential()\n",
    "model_gru_log.add(Input(shape=(68, 10)))\n",
    "model_gru_log.add(GRU(hidden_neurons, return_sequences = True))\n",
    "model_gru_log.add(TimeDistributed(Dense(1, activation = 'relu')))\n",
    "\n",
    "# compile GRU model\n",
    "model_gru_log.compile(optimizer=optimizer, loss=loss)\n",
    "model_gru_log.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "08D_AVpiB5wH",
    "outputId": "d35a856f-593b-4b7f-c410-2c1a89d8affe"
   },
   "outputs": [],
   "source": [
    "# fit model\n",
    "history_gru_log = model_gru_log.fit(np.array(X_train), np.log(np.array(y_train) + 1) , batch_size=batch_size, epochs=epochs, \n",
    "                    validation_data=(np.array(X_test), np.log(np.array(y_test) + 1)), verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zZCinof2nYds"
   },
   "source": [
    "Next we switched to an LSTM model on the log of the number of cases in each county. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "MABfN8eJVqWC",
    "outputId": "c6dd9a1e-161c-47e8-90c4-f03acd0368ef"
   },
   "outputs": [],
   "source": [
    "# LSTM model parameters\n",
    "hidden_neurons = 100\n",
    "optimizer = \"adam\"\n",
    "loss = \"MSE\"\n",
    "batch_size = 8\n",
    "epochs = 100\n",
    "verbose = 2\n",
    "\n",
    "# define LSTM model\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(Input(shape=(68, 10)))\n",
    "model_lstm.add(LSTM(hidden_neurons, return_sequences = True))\n",
    "model_lstm.add(TimeDistributed(Dense(1, activation = 'relu')))\n",
    "\n",
    "# compile LSTM model\n",
    "model_lstm.compile(optimizer=optimizer, loss=loss)\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "9Xke9QIILZdW",
    "outputId": "cadca42b-e221-434b-e71c-d361966e1cd1"
   },
   "outputs": [],
   "source": [
    "# fit model\n",
    "history_lstm = model_lstm.fit(np.array(X_train), np.log(np.array(y_train) + 1) , batch_size=batch_size, epochs=epochs, \n",
    "                    validation_data=(np.array(X_test), np.log(np.array(y_test) + 1)), verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J0FXbXoYnenN"
   },
   "source": [
    "We then ran the same LSTM model on the log of the number of cases but using a much smaller number of hidden neurons. We wanted to test if a smaller LSTM could capture simpler patterns in the data and reduce volatility in our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "q3oWdOiWVn8r",
    "outputId": "caec1fdf-b1a4-470a-b9f8-17b97e3e0ffa"
   },
   "outputs": [],
   "source": [
    "# LSTM model parameters\n",
    "hidden_neurons = 10\n",
    "optimizer = \"adam\"\n",
    "loss = \"MSE\"\n",
    "batch_size = 8\n",
    "epochs = 50\n",
    "verbose = 2\n",
    "\n",
    "# define LSTM model\n",
    "model_lstm_mini = Sequential()\n",
    "model_lstm_mini.add(Input(shape=(68, 10)))\n",
    "model_lstm_mini.add(LSTM(hidden_neurons, return_sequences = True))\n",
    "model_lstm_mini.add(TimeDistributed(Dense(1, activation = 'relu')))\n",
    "\n",
    "# compile LSTM model\n",
    "model_lstm_mini.compile(optimizer=optimizer, loss=loss)\n",
    "model_lstm_mini.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7xWZ0pStyi7B",
    "outputId": "37fc7e97-8013-414a-a543-6f15b76871a2"
   },
   "outputs": [],
   "source": [
    "# fit model\n",
    "history_lstm_mini = model_lstm_mini.fit(np.array(X_train), np.log(np.array(y_train) + 1) , batch_size=batch_size, epochs=epochs, \n",
    "                    validation_data=(np.array(X_test), np.log(np.array(y_test) + 1)), verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zjlVp9L7n6hq"
   },
   "source": [
    "Finally, we decided to use the original LSTM architecture, this time attempting to predict the number of new cases rather than the cumulative number of cases for each county. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bqa6Uyr02Foo"
   },
   "outputs": [],
   "source": [
    "# y vectors based on daily new cases\n",
    "y_train_new_cases = []\n",
    "for county in y_train:\n",
    "    new_cases = [0]\n",
    "    for i in range(1, len(county)):\n",
    "        new_cases.append(county[i] - county[i-1])\n",
    "    y_train_new_cases.append(new_cases)\n",
    "\n",
    "y_test_new_cases = []\n",
    "for county in y_test:\n",
    "    new_cases = [0]\n",
    "    for i in range(1, len(county)):\n",
    "        new_cases.append(county[i] - county[i-1])\n",
    "    y_test_new_cases.append(new_cases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "zgFzVz6kVghS",
    "outputId": "d593583a-a354-4451-ad6e-37ce1cd2b702"
   },
   "outputs": [],
   "source": [
    "# LSTM model parameters\n",
    "hidden_neurons = 100\n",
    "optimizer = \"adam\"\n",
    "loss = \"MSE\"\n",
    "batch_size = 8\n",
    "epochs = 100\n",
    "verbose = 2\n",
    "\n",
    "# define LSTM model\n",
    "model_lstm_new_cases = Sequential()\n",
    "model_lstm_new_cases.add(Input(shape=(68, 10)))\n",
    "model_lstm_new_cases.add(LSTM(hidden_neurons, return_sequences = True))\n",
    "model_lstm_new_cases.add(TimeDistributed(Dense(1, activation = 'relu')))\n",
    "\n",
    "# compile LSTM model\n",
    "model_lstm_new_cases.compile(optimizer=optimizer, loss=loss)\n",
    "model_lstm_new_cases.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "rOBOsAYBz4cS",
    "outputId": "8128d94a-103d-4d61-c1e4-a526b4b4df48"
   },
   "outputs": [],
   "source": [
    "# fit model\n",
    "history_lstm_new_cases = model_lstm_new_cases.fit(np.array(X_train), np.array(y_train_new_cases), batch_size=batch_size, epochs=epochs, \n",
    "                    validation_data=(np.array(X_test), np.array(y_test_new_cases)), verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "F9hi8PMSSquN",
    "outputId": "b7f6ed05-2c30-4478-8f37-a707930ec0df"
   },
   "outputs": [],
   "source": [
    "# Save weights for each model above\n",
    "model_gru.save_weights('model_gru.h5')\n",
    "model_gru_log.save_weights('model_gru_log.h5')\n",
    "model_lstm.save_weights('model_lstm.h5')\n",
    "model_lstm_mini.save_weights('model_lstm_mini.h5')\n",
    "model_lstm_new_cases.save_weights('model_lstm_new_cases.h5')\n",
    "\n",
    "# training accuracy plotted by epoch\n",
    "plot_training_history(history_gru)\n",
    "plot_training_history(history_gru_log)\n",
    "plot_training_history(history_lstm)\n",
    "plot_training_history(history_lstm_mini)\n",
    "plot_training_history(history_lstm_new_cases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O1qSLYLYVOg2"
   },
   "outputs": [],
   "source": [
    "# load saved models\n",
    "model_gru.load_weights('model_gru.h5')\n",
    "model_gru_log.load_weights('model_gru_log.h5')\n",
    "model_lstm.load_weights('model_lstm.h5')\n",
    "model_lstm_mini.load_weights('model_lstm_mini.h5')\n",
    "model_lstm_new_cases.load_weights('model_lstm_new_cases.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PMuIOsW0oKnG"
   },
   "source": [
    "The LSTM models resulted in much lower losses accross the datasets as compared to the GRU models. We plotted the cumulative predicted and actual number of cases for each county in the test set for each model from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "hefilC260O_Q",
    "outputId": "903b0729-5386-4567-97b9-8be41c273743"
   },
   "outputs": [],
   "source": [
    "# plot test predictions and label by county name from original GRU model\n",
    "\n",
    "# traceback each county in test to find county name\n",
    "fips = []\n",
    "for row in X_test:\n",
    "    for tup in df_merged.itertuples():\n",
    "        if row[-1] == (tup.retail_and_recreation_percent_change_from_baseline, tup.grocery_and_pharmacy_percent_change_from_baseline, \n",
    "                   tup.parks_percent_change_from_baseline,tup.transit_stations_percent_change_from_baseline, \n",
    "                   tup.workplaces_percent_change_from_baseline, tup.residential_percent_change_from_baseline, tup.temperature, tup.rain, tup.sun, tup.density):\n",
    "            fips.append(tup.fips)\n",
    " \n",
    "# plot true cases and predicted cases over time for test data\n",
    "fig, ax = plt.subplots(17, 3, figsize=(15, 80))\n",
    "\n",
    "predicted_cases = model_gru.predict(X_test)\n",
    "for i in range(51):\n",
    "    ax[i // 3][i % 3].plot(np.arange(0, 68) , predicted_cases[i], label = 'Predicted Cases')\n",
    "    ax[i // 3][i % 3].plot(np.arange(0, 68) , y_test[i], label = 'True Cases')\n",
    "    ax[i // 3][i % 3].set_title(df_merged.loc[df_merged['fips'] == fips[i]]['state_county'].iloc[0])\n",
    "    ax[i // 3][i % 3].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MxfgaPYy0XYd",
    "outputId": "3a74d4e8-d19f-4147-ab37-cf78e7bf1e05"
   },
   "outputs": [],
   "source": [
    "# plot test predictions and label by county name from original GRU model on log of cumulative cases\n",
    "fig, ax = plt.subplots(17, 3, figsize=(15, 80))\n",
    "\n",
    "predicted_cases = model_gru_log.predict(X_test)\n",
    "for i in range(51):\n",
    "    ax[i // 3][i % 3].plot(np.arange(0, 68) , np.exp(predicted_cases[i]) - 1, label = 'Predicted Cases')\n",
    "    ax[i // 3][i % 3].plot(np.arange(0, 68) , y_test[i], label = 'True Cases')\n",
    "    ax[i // 3][i % 3].set_title(df_merged.loc[df_merged['fips'] == fips[i]]['state_county'].iloc[0])\n",
    "    ax[i // 3][i % 3].legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "iz25MbrETn4p",
    "outputId": "24d1f57a-be53-4968-dd70-d1778e285ebe"
   },
   "outputs": [],
   "source": [
    "# plot test predictions and label by county name from original LSTM model on log of cumulative cases\n",
    "\n",
    "# plot true cases and predicted cases over time for test data\n",
    "fig, ax = plt.subplots(17, 3, figsize=(15, 80))\n",
    "\n",
    "predicted_cases = model_lstm.predict(X_test)\n",
    "for i in range(51):\n",
    "    ax[i // 3][i % 3].plot(np.arange(0, 68) , np.exp(predicted_cases[i]) - 1, label = 'Predicted Cases')\n",
    "    ax[i // 3][i % 3].plot(np.arange(0, 68) , y_test[i], label = 'True Cases')\n",
    "    ax[i // 3][i % 3].set_title(df_merged.loc[df_merged['fips'] == fips[i]]['state_county'].iloc[0])\n",
    "    ax[i // 3][i % 3].legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "PvQVoE6czeX6",
    "outputId": "bdfcb0bb-8d18-4c69-fcd6-956c26a931dc"
   },
   "outputs": [],
   "source": [
    "# plot test predictions and label by county name from LSTM model wither fewer hidden neurons on log of cumulative cases\n",
    "fig, ax = plt.subplots(17, 3, figsize=(15, 80))\n",
    "\n",
    "predicted_cases = model_lstm_mini.predict(X_test)\n",
    "for i in range(51):\n",
    "    ax[i // 3][i % 3].plot(np.arange(0, 68) , np.exp(predicted_cases[i]) - 1, label = 'Predicted Cases')\n",
    "    ax[i // 3][i % 3].plot(np.arange(0, 68) , y_test[i], label = 'True Cases')\n",
    "    ax[i // 3][i % 3].set_title(df_merged.loc[df_merged['fips'] == fips[i]]['state_county'].iloc[0])\n",
    "    ax[i // 3][i % 3].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "n7L8eVal226H",
    "outputId": "0fbe90bf-c490-45b6-df0d-f0138aed68a8"
   },
   "outputs": [],
   "source": [
    "# plot test predictions and label by county name from LSTM model trained on daily new cases\n",
    "fig, ax = plt.subplots(17, 3, figsize=(15, 80))\n",
    "\n",
    "predicted_new_cases = model_lstm_new_cases.predict(X_test)\n",
    "for i in range(51):\n",
    "    \n",
    "    pred_cumulative_cases = predicted_new_cases[i][0]\n",
    "    for j in range(1, 68):\n",
    "        pred_cumulative_cases = np.append(pred_cumulative_cases, predicted_new_cases[i][j] + pred_cumulative_cases[j - 1])\n",
    "\n",
    "    ax[i // 3][i % 3].plot(np.arange(0, 68) , pred_cumulative_cases, label = 'Predicted Cases')\n",
    "    ax[i // 3][i % 3].plot(np.arange(0, 68) , y_test[i], label = 'True Cases')\n",
    "    ax[i // 3][i % 3].set_title(df_merged.loc[df_merged['fips'] == fips[i]]['state_county'].iloc[0])\n",
    "    ax[i // 3][i % 3].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I-LO209To5GM"
   },
   "source": [
    "## Discussion of RNN Models\n",
    "\n",
    "The largest difference in model performance resulted from using the log of cases rather than the total number of cases. This is most likely because the model could more easily predict a linear relationship rather than an exponential relationship given the small sample size of only 500 counties.\n",
    "\n",
    "Additionally, training a smaller LSTM model resulted in the number of cases increasing in large increments rather than a continuous fashion.\n",
    "\n",
    "Finally, predicting new cases rather than cumulative cases smoothed out much the model's ouput but also decreased accuracy slightly. It seems this model could more accurately model exponential growth but lacked much of the granularity of the LSTM and GRU models trained on the log number of cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uh-XpKgmiHjW"
   },
   "source": [
    "# Aggregate Data by County"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_a6FCatosMR"
   },
   "source": [
    "In addition to the above models, we looked for correlations between the various predictors and R-proxy values for each county. We began by aggregating data by county and deriving R-proxy levels for each county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "colab_type": "code",
    "id": "DZxhHUw_wUuS",
    "outputId": "0f2adfeb-f913-4b0b-d81e-3a5e945eaafe"
   },
   "outputs": [],
   "source": [
    "# split cases by county\n",
    "cases_by_county = df_merged.loc[df_merged['state_county'] == 'Arizona Maricopa'].groupby('date').agg({'cases':'sum'})\n",
    "cases_by_county = cases_by_county.rename(columns={'cases':'Arizona Maricopa'})\n",
    "\n",
    "for state_county in df_merged['state_county'].unique():\n",
    "    if state_county != 'Arizona Maricopa':\n",
    "        new_county = df_merged.loc[df_merged['state_county'] == state_county].groupby('date').agg({'cases':'sum'})\n",
    "        new_county = new_county.rename(columns={'cases':state_county})\n",
    "        cases_by_county = cases_by_county.join(new_county)\n",
    "\n",
    "cases_by_county = cases_by_county.fillna(0).reset_index().drop('date', axis=1)\n",
    "cases_by_county.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hGF75fPu53VV"
   },
   "outputs": [],
   "source": [
    "# find mean \n",
    "temp_by_county = df_merged.groupby('state_county').agg({'temperature':'mean'})\n",
    "rain_by_county = df_merged.groupby('state_county').agg({'rain':'mean'})\n",
    "sun_by_county = df_merged.groupby('state_county').agg({'sun':'mean'})\n",
    "density_by_county = df_merged.groupby('state_county').agg({'density':'mean'})\n",
    "residential_mobility_by_county = df_merged.groupby('state_county').agg({'residential_percent_change_from_baseline':'mean'})\n",
    "parks_mobility_by_county = df_merged.groupby('state_county').agg({'parks_percent_change_from_baseline':'mean'})\n",
    "grocery_mobility_by_county = df_merged.groupby('state_county').agg({'grocery_and_pharmacy_percent_change_from_baseline':'mean'})\n",
    "retail_mobility_by_county = df_merged.groupby('state_county').agg({'retail_and_recreation_percent_change_from_baseline':'mean'})\n",
    "transit_mobility_by_county = df_merged.groupby('state_county').agg({'transit_stations_percent_change_from_baseline':'mean'})\n",
    "workplaces_mobility_by_county = df_merged.groupby('state_county').agg({'workplaces_percent_change_from_baseline':'mean'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iuIXSF-_ZBoJ"
   },
   "outputs": [],
   "source": [
    "# find r_proxy over a data frame\n",
    "def r_proxy(start, d, data):\n",
    "    ans = []\n",
    "    for t in range(start, len(data)-2*d):\n",
    "        ans.append((data.iloc[t+2*d]-data.iloc[t+d]) / (data.iloc[t+d]-data.iloc[t]))\n",
    "    return pd.DataFrame(ans).replace([np.inf, -np.inf], np.nan).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "-jDNvZei3AvR",
    "outputId": "c8486449-f1ee-4903-ab19-1806b93a7c09"
   },
   "outputs": [],
   "source": [
    "# find r_proxy by county\n",
    "r0s_by_county = r_proxy(35, 5, cases_by_county)\n",
    "\n",
    "# plot bargraph of r_proxy by county\n",
    "x = np.arange(0, cases_by_county.shape[1] + 10, (cases_by_county.shape[1] + 10) / cases_by_county.shape[1])[:-1]\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.bar(x, r0s_by_county.mean(), width=1)\n",
    "# plt.xticks(x, labels = r0s_by_county.columns, rotation=90)\n",
    "plt.ylabel('R0-Proxy')\n",
    "plt.xlabel('County')\n",
    "plt.title('R0-Proxy by County')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "WI130hWTBU9d",
    "outputId": "223c4c19-73c2-4ac2-fc24-a50f467a282e"
   },
   "outputs": [],
   "source": [
    "# print('Max R0:', r0s_by_county.columns[np.argmax(r0s_by_county.mean())])\n",
    "\n",
    "# print('Min R0:', r0s_by_county.columns[np.argmin(r0s_by_county.mean())])\n",
    "\n",
    "\n",
    "\n",
    "print('Max R0:', r0s_by_county.mean()[r0s_by_county.mean() > 3 ])\n",
    "\n",
    "print('Min R0:', r0s_by_county.mean()[r0s_by_county.mean() < -4 ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GYN4LGg2BHro"
   },
   "source": [
    "The bar graph above demonstrates the variability in R-proxy values accross the country. Some counties had extremely high R-proxy values (like Richmond Georgia with an R-proxy of about 10.5) while others had much lower averages (like Butler Pennsylvania with an R-proxy of roughly -4.5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sOncCtuliWjw"
   },
   "source": [
    "# Regression on R-proxy Values and Predictors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZBCNj9p7pSZY"
   },
   "source": [
    "Below we calculated and plotted R-proxy values against the various predictors of the above models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "7QbiCzE3rSkD",
    "outputId": "a6f56eef-17a8-47c2-8ed9-30b84e16ef1b"
   },
   "outputs": [],
   "source": [
    "# plot R-proxy vs. Temperature\n",
    "sns.regplot(temp_by_county, r0s_by_county.mean())\n",
    "plt.ylabel('R0-Proxy')\n",
    "plt.title('R0-Proxy vs. Temperature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "s-TtFdC_icz_",
    "outputId": "ba67ea24-314d-4e13-a9c9-36c2f56ccd46"
   },
   "outputs": [],
   "source": [
    "# plot R-proxy vs. Rain \n",
    "sns.regplot(rain_by_county, r0s_by_county.mean())\n",
    "plt.ylabel('R0-Proxy')\n",
    "plt.title('R0-Proxy vs. Rain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "Rn1jPagnieUf",
    "outputId": "945b7083-0587-4e85-83af-b8eb721a6084"
   },
   "outputs": [],
   "source": [
    "# plot R-proxy vs. Sun \n",
    "sns.regplot(sun_by_county, r0s_by_county.mean())\n",
    "plt.ylabel('R0-Proxy')\n",
    "plt.title('R0-Proxy vs. Sun')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "Vxc8jOAWifkB",
    "outputId": "104f4d16-514e-4518-e6ac-88efe5a71281"
   },
   "outputs": [],
   "source": [
    "# plot R-proxy vs. Density\n",
    "sns.regplot(density_by_county.values, r0s_by_county.mean())\n",
    "plt.ylabel('R0-Proxy')\n",
    "plt.title('R0-Proxy vs. Density')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "BI4fP7_LigrB",
    "outputId": "30648866-5195-43d1-ca7b-06e8cebe6862"
   },
   "outputs": [],
   "source": [
    "# plot R-proxy vs. Residential Mobility \n",
    "sns.regplot(residential_mobility_by_county, r0s_by_county.mean())\n",
    "plt.ylabel('R0-Proxy')\n",
    "plt.title('R0-Proxy vs. Residential Mobility')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "NxcMNnI_iiCw",
    "outputId": "2a49ee61-a585-4e5e-96db-11751da28eef"
   },
   "outputs": [],
   "source": [
    "# plot R-proxy vs. Retail Mobility\n",
    "sns.regplot(retail_mobility_by_county, r0s_by_county.mean())\n",
    "plt.ylabel('R0-Proxy')\n",
    "plt.title('R0-Proxy vs. Retail Mobility')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "f79HxU00iitw",
    "outputId": "9ebf1667-b393-433e-cf15-690d3db9d7c2"
   },
   "outputs": [],
   "source": [
    "# plot R-proxy vs. Parks Mobility\n",
    "sns.regplot(parks_mobility_by_county, r0s_by_county.mean())\n",
    "plt.ylabel('R0-Proxy')\n",
    "plt.title('R0-Proxy vs. Parks Mobility')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "t3pqNFOKijUU",
    "outputId": "8a83428a-50a0-4258-d694-3ec82e2f3e2a"
   },
   "outputs": [],
   "source": [
    "# plot R-proxy vs. Transit Mobility\n",
    "sns.regplot(transit_mobility_by_county, r0s_by_county.mean())\n",
    "plt.ylabel('R0-Proxy')\n",
    "plt.title('R0-Proxy vs. Transit Mobility')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "Rowu1ZcyikAG",
    "outputId": "defa0f42-a4c5-42b1-e9af-6ad0908580e9"
   },
   "outputs": [],
   "source": [
    "# plot R-proxy vs. Grocery Mobility\n",
    "sns.regplot(grocery_mobility_by_county, r0s_by_county.mean())\n",
    "plt.ylabel('R0-Proxy')\n",
    "plt.title('R0-Proxy vs. Grocery Mobility')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "uASaeq33eiDK",
    "outputId": "b9e15f2d-234a-4f86-c702-7ddde4f65c18"
   },
   "outputs": [],
   "source": [
    "# plot R-proxy vs. Work Mobility\n",
    "sns.regplot(workplaces_mobility_by_county, r0s_by_county.mean())\n",
    "plt.ylabel('R0-Proxy')\n",
    "plt.title('R0-Proxy vs. Work Mobility')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 684
    },
    "colab_type": "code",
    "id": "WEigR-zQioYG",
    "outputId": "bd867fca-5ee8-43c3-ac6e-3fdac6b54322"
   },
   "outputs": [],
   "source": [
    "# Summarize overall regression\n",
    "exog = ['retail_and_recreation_percent_change_from_baseline',\n",
    "       'grocery_and_pharmacy_percent_change_from_baseline',\n",
    "       'parks_percent_change_from_baseline',\n",
    "       'transit_stations_percent_change_from_baseline',\n",
    "       'workplaces_percent_change_from_baseline',\n",
    "       'residential_percent_change_from_baseline', 'temperature', 'density', 'sun', 'rain']\n",
    "\n",
    "\n",
    "OLS = fit_OLS(data, exog, 'cases' )\n",
    "OLS.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4xWrzD9BtO7y"
   },
   "source": [
    "## Discussion of Regressions\n",
    "\n",
    "\n",
    "The regressions we performed as well as the summary output indicate relatively low correlations between R-proxy and the predictors we used here. The OLS summary directly above actually shows negative coefficients for much of the mobility predictors. Many counties imposed stay-at-home orders when cases and R-proxy began to increase. This would indicate that mobility in these areas decreased with higher R-proxies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iRxBmCCbAFTJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SKugSRy5QYjh"
   },
   "source": [
    "# Sources:\n",
    "\n",
    "*   Google Mobility Reports https://www.google.com/covid19/mobility/\n",
    "*   Luo, Wei, et al. The Role of Absolute Humidity on Transmission Rates of the COVID-19 Outbreak. 2020, doi:10.1101/2020.02.12.20022467.\n",
    "* World Weather Online https://www.worldweatheronline.com/ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IZiczucKQcqJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "projectDmilestone3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
